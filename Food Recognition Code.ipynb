{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eecc050c",
   "metadata": {
    "papermill": {
     "duration": 0.003461,
     "end_time": "2025-01-08T10:29:36.129265",
     "exception": false,
     "start_time": "2025-01-08T10:29:36.125804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORT LIBRARIES AND LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65b3b2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T10:29:36.137207Z",
     "iopub.status.busy": "2025-01-08T10:29:36.136680Z",
     "iopub.status.idle": "2025-01-08T10:29:53.797591Z",
     "shell.execute_reply": "2025-01-08T10:29:53.796075Z"
    },
    "papermill": {
     "duration": 17.667084,
     "end_time": "2025-01-08T10:29:53.799453",
     "exception": true,
     "start_time": "2025-01-08T10:29:36.132369",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 9, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Define parameters\u001b[39;00m\n\u001b[1;32m     10\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/food-image-classification-dataset/Food Classification dataset\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Path to the directory with images\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m nutrition_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/nutrition-info-csv/nutrition-info\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m     13\u001b[0m img_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m224\u001b[39m  \u001b[38;5;66;03m# Standard input size for MobileNetV2\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 9, saw 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define parameters\n",
    "data_dir = '/kaggle/input/food-image-classification-dataset/Food Classification dataset'  # Path to the directory with images\n",
    "nutrition_df = pd.read_csv('/kaggle/input/nutrition-info-csv/nutrition-info')\n",
    "batch_size = 32\n",
    "img_height = 224  # Standard input size for MobileNetV2\n",
    "img_width = 224\n",
    "validation_split = 0.2  # 20% of data used for validation\n",
    "\n",
    "# Data augmentation and normalization\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    validation_split=validation_split,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create train and validation generators\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f59b57",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# CNN MODEL WITH MOBILENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da40de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T15:17:18.062862Z",
     "iopub.status.busy": "2024-10-30T15:17:18.062090Z",
     "iopub.status.idle": "2024-10-30T15:17:18.357604Z",
     "shell.execute_reply": "2024-10-30T15:17:18.356473Z",
     "shell.execute_reply.started": "2024-10-30T15:17:18.062800Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(len(train_generator.class_indices), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b0af71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T15:18:47.687735Z",
     "iopub.status.busy": "2024-10-30T15:18:47.687248Z",
     "iopub.status.idle": "2024-10-30T15:18:48.568478Z",
     "shell.execute_reply": "2024-10-30T15:18:48.567513Z",
     "shell.execute_reply.started": "2024-10-30T15:18:47.687688Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display class names\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# Load the MobileNetV2 model pre-trained on ImageNet without the top layer\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "base_model.trainable = False  # Freeze the base model layers to retain pre-trained features\n",
    "\n",
    "# Build the model on top of MobileNetV2\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(class_names), activation='softmax')  # Adjust for the number of classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8572ef2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-30T15:18:53.155331Z",
     "iopub.status.busy": "2024-10-30T15:18:53.154872Z",
     "iopub.status.idle": "2024-10-30T15:33:47.314314Z",
     "shell.execute_reply": "2024-10-30T15:33:47.311465Z",
     "shell.execute_reply.started": "2024-10-30T15:18:53.155290Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display class names\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# Display a few sample images from the dataset with labels\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_generator:\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(class_names[int(labels[i])])\n",
    "        plt.axis(\"off\")\n",
    "    break\n",
    "\n",
    "# Train the model\n",
    "epochs = 1  # Increase epochs for potentially better performance\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_acc = model.evaluate(validation_generator, verbose=2)\n",
    "print(\"\\nValidation accuracy:\", val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2259afa4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-30T15:33:47.317589Z",
     "iopub.status.idle": "2024-10-30T15:33:47.318056Z",
     "shell.execute_reply": "2024-10-30T15:33:47.317846Z",
     "shell.execute_reply.started": "2024-10-30T15:33:47.317823Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(train_generator, verbose =2)\n",
    "val_loss, val_acc = model.evaluate(validation_generator,verbose =2)\n",
    "\n",
    "print(f\"\\nFinal Training Accuracy: {train_acc:.2f}\")\n",
    "print(f\"Final Training Loss: {train_loss:.2f}\")\n",
    "print(f\"Final Validation Accuracy: {val_acc:.2f}\")\n",
    "print(f\"Final Validation Loss: {val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79c81c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-30T15:33:47.319834Z",
     "iopub.status.idle": "2024-10-30T15:33:47.320293Z",
     "shell.execute_reply": "2024-10-30T15:33:47.320095Z",
     "shell.execute_reply.started": "2024-10-30T15:33:47.320074Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2290708b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-30T15:33:47.321390Z",
     "iopub.status.idle": "2024-10-30T15:33:47.321815Z",
     "shell.execute_reply": "2024-10-30T15:33:47.321620Z",
     "shell.execute_reply.started": "2024-10-30T15:33:47.321599Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "validation_generator.reset()  # Reset the generator for new predictions\n",
    "predictions = model.predict(validation_generator, steps=validation_generator.samples // batch_size)\n",
    "predicted_classes = np.argmax(predictions, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Get true classes\n",
    "true_classes = validation_generator.classes\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb298ce",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to predict food item and nutritional values\n",
    "def predict_nutrition(image_path):\n",
    "    # Load and preprocess the image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    img = np.expand_dims(img, axis=0) / 255.0  # Normalize the image\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(img)\n",
    "    predicted_label_index = np.argmax(predictions[0])\n",
    "    predicted_food_item = label_encoder.inverse_transform([predicted_label_index])[0]\n",
    "\n",
    "    # Get nutritional information\n",
    "    nutritional_info = nutrition_df[nutrition_df['Food Label'] == predicted_food_item]\n",
    "    \n",
    "    if not nutritional_info.empty:\n",
    "        return predicted_food_item, nutritional_info.to_dict('records')[0]\n",
    "    else:\n",
    "        return predicted_food_item, None\n",
    "\n",
    "# Example usage\n",
    "sample_image_path = 'path_to_sample_image.jpg'  # Update with the path to your sample image\n",
    "predicted_food, nutrition = predict_nutrition(sample_image_path)\n",
    "\n",
    "# Output the results\n",
    "if nutrition is not None:\n",
    "    print(f\"Predicted Food Item: {predicted_food}\")\n",
    "    print(f\"Nutritional Information: {nutrition}\")\n",
    "else:\n",
    "    print(\"Nutritional information not found.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3480259,
     "sourceId": 6079287,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5980424,
     "sourceId": 9765114,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.825651,
   "end_time": "2025-01-08T10:29:55.428469",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-08T10:29:32.602818",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
